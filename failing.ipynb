{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# House Price Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# 1. Load the dataset\n",
    "# -----------------------------\n",
    "# Replace 'house_prices.csv' with the path to your dataset.\n",
    "data = pd.read_csv('train.csv')\n",
    "#data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# 2. Data Cleaning\n",
    "# -----------------------------\n",
    "# Select only numeric columns that have no missing data.\n",
    "numeric_cols = data.select_dtypes(include=[np.number]).columns\n",
    "clean_numeric_cols = [col for col in numeric_cols if data[col].isna().sum() == 0]\n",
    "data_clean = data[clean_numeric_cols]\n",
    "\n",
    "# Ensure that the target column 'price' is present.\n",
    "if 'SalePrice' not in data_clean.columns:\n",
    "    raise ValueError(\"The target column 'price' is not present in the complete numeric data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected top 4 features: ['OverallQual', 'GrLivArea', 'GarageCars', 'GarageArea']\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# 3. Feature Selection\n",
    "# -----------------------------\n",
    "# Compute the correlation matrix using only the cleaned numeric data.\n",
    "corr_matrix = data_clean.corr()\n",
    "\n",
    "# Compute absolute correlations of features with the target and drop the target itself.\n",
    "target_corr = corr_matrix['SalePrice'].drop('SalePrice').abs().sort_values(ascending=False)\n",
    "\n",
    "# Select only the top 4 features with the highest correlation with 'SalesPrice'\n",
    "top4_features = target_corr.head(4).index\n",
    "print(\"Selected top 4 features:\", list(top4_features))\n",
    "\n",
    "# Define input features (X) and target variable (y).\n",
    "X = data_clean[top4_features].values\n",
    "y = data_clean['SalePrice'].values.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# 4. Data Preprocessing\n",
    "# -----------------------------\n",
    "# Split the data into training and testing sets.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize features to improve training stability.\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the numpy arrays to PyTorch tensors.\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "# Create a TensorDataset and DataLoader for batch processing.\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImprovedHousePriceModel(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(ImprovedHousePriceModel, self).__init__()\n",
    "        # First layer: increase capacity\n",
    "        self.fc1 = nn.Linear(input_dim, 128)\n",
    "        self.bn1 = nn.BatchNorm1d(128)\n",
    "        self.dropout1 = nn.Dropout(0.2)\n",
    "        \n",
    "        # Second layer: reduce dimensionality\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.bn2 = nn.BatchNorm1d(64)\n",
    "        self.dropout2 = nn.Dropout(0.2)\n",
    "        \n",
    "        # Third layer: further reduction\n",
    "        self.fc3 = nn.Linear(64, 32)\n",
    "        self.bn3 = nn.BatchNorm1d(32)\n",
    "        self.dropout3 = nn.Dropout(0.2)\n",
    "        \n",
    "        # Output layer for regression\n",
    "        self.fc4 = nn.Linear(32, 1)\n",
    "        \n",
    "        # Activation function: LeakyReLU with a small negative slope\n",
    "        self.leaky_relu = nn.LeakyReLU(negative_slope=0.01)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.leaky_relu(x)\n",
    "        x = self.dropout1(x)\n",
    "        \n",
    "        x = self.fc2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.leaky_relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        \n",
    "        x = self.fc3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.leaky_relu(x)\n",
    "        x = self.dropout3(x)\n",
    "        \n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "\n",
    "# Use GPU if available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = ImprovedHousePriceModel(input_dim=X_train.shape[1]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/1000], Loss: 41064929034.2400\n",
      "Epoch [20/1000], Loss: 41056994508.8000\n",
      "Epoch [30/1000], Loss: 41043288965.1200\n",
      "Epoch [40/1000], Loss: 41025419427.8400\n",
      "Epoch [50/1000], Loss: 41003205345.2800\n",
      "Epoch [60/1000], Loss: 40977375477.7600\n",
      "Epoch [70/1000], Loss: 40947795476.4800\n",
      "Epoch [80/1000], Loss: 40913678336.0000\n",
      "Epoch [90/1000], Loss: 40877707345.9200\n",
      "Epoch [100/1000], Loss: 40840286781.4400\n",
      "Epoch [110/1000], Loss: 40800603668.4800\n",
      "Epoch [120/1000], Loss: 40751797944.3200\n",
      "Epoch [130/1000], Loss: 40707003678.7200\n",
      "Epoch [140/1000], Loss: 40653399244.8000\n",
      "Epoch [150/1000], Loss: 40602283622.4000\n",
      "Epoch [160/1000], Loss: 40546331279.3600\n",
      "Epoch [170/1000], Loss: 40488873820.1600\n",
      "Epoch [180/1000], Loss: 40429498449.9200\n",
      "Epoch [190/1000], Loss: 40370426429.4400\n",
      "Epoch [200/1000], Loss: 40301921812.4800\n",
      "Epoch [210/1000], Loss: 40239824896.0000\n",
      "Epoch [220/1000], Loss: 40165294735.3600\n",
      "Epoch [230/1000], Loss: 40096819937.2800\n",
      "Epoch [240/1000], Loss: 40013408747.5200\n",
      "Epoch [250/1000], Loss: 39942828769.2800\n",
      "Epoch [260/1000], Loss: 39870581882.8800\n",
      "Epoch [270/1000], Loss: 39795966525.4400\n",
      "Epoch [280/1000], Loss: 39693250314.2400\n",
      "Epoch [290/1000], Loss: 39601954406.4000\n",
      "Epoch [300/1000], Loss: 39530728816.6400\n",
      "Epoch [310/1000], Loss: 39460193894.4000\n",
      "Epoch [320/1000], Loss: 39348982661.1200\n",
      "Epoch [330/1000], Loss: 39275273175.0400\n",
      "Epoch [340/1000], Loss: 39171217244.1600\n",
      "Epoch [350/1000], Loss: 39074334883.8400\n",
      "Epoch [360/1000], Loss: 38982466682.8800\n",
      "Epoch [370/1000], Loss: 38864845455.3600\n",
      "Epoch [380/1000], Loss: 38786023587.8400\n",
      "Epoch [390/1000], Loss: 38669385728.0000\n",
      "Epoch [400/1000], Loss: 38580991590.4000\n",
      "Epoch [410/1000], Loss: 38456695029.7600\n",
      "Epoch [420/1000], Loss: 38366424104.9600\n",
      "Epoch [430/1000], Loss: 38232093163.5200\n",
      "Epoch [440/1000], Loss: 38106451968.0000\n",
      "Epoch [450/1000], Loss: 38016495616.0000\n",
      "Epoch [460/1000], Loss: 37883250688.0000\n",
      "Epoch [470/1000], Loss: 37736668364.8000\n",
      "Epoch [480/1000], Loss: 37655178117.1200\n",
      "Epoch [490/1000], Loss: 37544734392.3200\n",
      "Epoch [500/1000], Loss: 37410772746.2400\n",
      "Epoch [510/1000], Loss: 37278241341.4400\n",
      "Epoch [520/1000], Loss: 37173416263.6800\n",
      "Epoch [530/1000], Loss: 37002722344.9600\n",
      "Epoch [540/1000], Loss: 36896387645.4400\n",
      "Epoch [550/1000], Loss: 36806114099.2000\n",
      "Epoch [560/1000], Loss: 36639767838.7200\n",
      "Epoch [570/1000], Loss: 36472595578.8800\n",
      "Epoch [580/1000], Loss: 36350438522.8800\n",
      "Epoch [590/1000], Loss: 36153683476.4800\n",
      "Epoch [600/1000], Loss: 36034010890.2400\n",
      "Epoch [610/1000], Loss: 35926504734.7200\n",
      "Epoch [620/1000], Loss: 35797484748.8000\n",
      "Epoch [630/1000], Loss: 35634745180.1600\n",
      "Epoch [640/1000], Loss: 35483189739.5200\n",
      "Epoch [650/1000], Loss: 35374970716.1600\n",
      "Epoch [660/1000], Loss: 35189718876.1600\n",
      "Epoch [670/1000], Loss: 35094043115.5200\n",
      "Epoch [680/1000], Loss: 34865802199.0400\n",
      "Epoch [690/1000], Loss: 34717758259.2000\n",
      "Epoch [700/1000], Loss: 34613066137.6000\n",
      "Epoch [710/1000], Loss: 34446638448.6400\n",
      "Epoch [720/1000], Loss: 34275297361.9200\n",
      "Epoch [730/1000], Loss: 34054361088.0000\n",
      "Epoch [740/1000], Loss: 33943403724.8000\n",
      "Epoch [750/1000], Loss: 33830958858.2400\n",
      "Epoch [760/1000], Loss: 33623099064.3200\n",
      "Epoch [770/1000], Loss: 33397271920.6400\n",
      "Epoch [780/1000], Loss: 33219698114.5600\n",
      "Epoch [790/1000], Loss: 33064870625.2800\n",
      "Epoch [800/1000], Loss: 33030848266.2400\n",
      "Epoch [810/1000], Loss: 32688461905.9200\n",
      "Epoch [820/1000], Loss: 32558551859.2000\n",
      "Epoch [830/1000], Loss: 32340548648.9600\n",
      "Epoch [840/1000], Loss: 32291495280.6400\n",
      "Epoch [850/1000], Loss: 32113523138.5600\n",
      "Epoch [860/1000], Loss: 31811886448.6400\n",
      "Epoch [870/1000], Loss: 31674348175.3600\n",
      "Epoch [880/1000], Loss: 31511567319.0400\n",
      "Epoch [890/1000], Loss: 31342932377.6000\n",
      "Epoch [900/1000], Loss: 31088139714.5600\n",
      "Epoch [910/1000], Loss: 31026983567.3600\n",
      "Epoch [920/1000], Loss: 30866854461.4400\n",
      "Epoch [930/1000], Loss: 30528387645.4400\n",
      "Epoch [940/1000], Loss: 30417300111.3600\n",
      "Epoch [950/1000], Loss: 30137111265.2800\n",
      "Epoch [960/1000], Loss: 29940649082.8800\n",
      "Epoch [970/1000], Loss: 29894502481.9200\n",
      "Epoch [980/1000], Loss: 29662599249.9200\n",
      "Epoch [990/1000], Loss: 29517263749.1200\n",
      "Epoch [1000/1000], Loss: 29234801131.5200\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# 6. Set Up Loss Function and Optimizer\n",
    "# -----------------------------\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# -----------------------------\n",
    "# 7. Train the Model\n",
    "# -----------------------------\n",
    "num_epochs = 1000\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for batch_X, batch_y in train_loader:\n",
    "        batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_X)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item() * batch_X.size(0)\n",
    "    \n",
    "    epoch_loss = running_loss / len(train_dataset)\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Mean Squared Error: 24636186624.0\n",
      "Test MSE (scikit-learn): 24636182528.0\n"
     ]
    }
   ],
   "source": [
    "# 8. Evaluate the Model\n",
    "# -----------------------------\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    predictions = model(X_test_tensor.to(device))\n",
    "    test_loss = criterion(predictions, y_test_tensor.to(device)).item()\n",
    "    print(\"Test Mean Squared Error:\", test_loss)\n",
    "\n",
    "# Optionally, to evaluate using scikit-learn's MSE:\n",
    "predictions_np = predictions.cpu().numpy()\n",
    "mse = mean_squared_error(y_test, predictions_np)\n",
    "print(\"Test MSE (scikit-learn):\", mse)\n",
    "#Test Mean Squared Error: 935741376.0\n",
    "#Test Mean Squared Error: 890287168.0\n",
    "#Test MSE (scikit-learn): 890287040.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training RMSE: 171498.48223235097\n",
      "Test RMSE: 156959.18776548252\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    train_predictions = model(X_train_tensor.to(device))\n",
    "    train_loss = criterion(train_predictions, y_train_tensor.to(device)).item()\n",
    "    train_rmse = np.sqrt(train_loss)\n",
    "    print(\"Training RMSE:\", train_rmse)\n",
    "\n",
    "rmse = np.sqrt(test_loss)\n",
    "print(f\"Test RMSE: {rmse}\")\n",
    "\n",
    "#Bella's Result: Training RMSE: 37040.67904345167\n",
    "#Test RMSE: 30354.362585961182"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_64633/3042700335.py:4: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
      "  errors = np.abs(predictions - y_test)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "errors = np.abs(predictions - y_test)\n",
    "sns.histplot(errors, bins=50, kde=True)\n",
    "plt.xlabel(\"Absolute Error ($)\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Distribution of Prediction Errors\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved to predictions.csv\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# 9. Generate Predictions on New Test Data (test.csv)\n",
    "# -----------------------------\n",
    "# Load the new test data\n",
    "test_data = pd.read_csv('test.csv')\n",
    "\n",
    "# Ensure the test data contains the ID column and the same top4_features.\n",
    "# For this example, assume the test file contains an \"ID\" column.\n",
    "if 'Id' not in test_data.columns:\n",
    "    raise ValueError(\"The test data must contain an 'ID' column.\")\n",
    "\n",
    "# It's assumed that the test data has at least the columns used in training.\n",
    "# Use the same top4_features determined from the training set.\n",
    "X_new = test_data[top4_features].values\n",
    "\n",
    "# Apply the same scaling transformation using the previously fitted scaler.\n",
    "X_new_scaled = scaler.transform(X_new)\n",
    "\n",
    "# Convert to PyTorch tensor.\n",
    "X_new_tensor = torch.tensor(X_new_scaled, dtype=torch.float32).to(device)\n",
    "\n",
    "# Put the model in evaluation mode and generate predictions.\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    new_predictions = model(X_new_tensor)\n",
    "    \n",
    "# Convert predictions to numpy array and flatten if necessary.\n",
    "new_predictions_np = new_predictions.cpu().numpy().flatten()\n",
    "\n",
    "# Create a DataFrame with IDs and their corresponding predicted sale prices.\n",
    "predictions_df = pd.DataFrame({\n",
    "    'ID': test_data['Id'],\n",
    "    'SalePrice': new_predictions_np\n",
    "})\n",
    "\n",
    "# Save the DataFrame to a CSV file.\n",
    "predictions_df.to_csv('predictions.csv', index=False)\n",
    "print(\"Predictions saved to predictions.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected top 4 features: ['OverallQual', 'GrLivArea', 'GarageCars', 'GarageArea']\n",
      "Epoch [1/300] - Train Loss: 42325493043.2000, Val Loss: 36036862771.2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/300] - Train Loss: 42323569868.8000, Val Loss: 36035288678.4000\n",
      "Epoch [20/300] - Train Loss: 42320763596.8000, Val Loss: 36033165312.0000\n",
      "Epoch [30/300] - Train Loss: 42317797683.2000, Val Loss: 36030724096.0000\n",
      "Epoch [40/300] - Train Loss: 42316175462.4000, Val Loss: 36029646438.4000\n",
      "Epoch [50/300] - Train Loss: 42314354995.2000, Val Loss: 36028115763.2000\n",
      "Epoch [60/300] - Train Loss: 42313430937.6000, Val Loss: 36027395686.4000\n",
      "Epoch [70/300] - Train Loss: 42313093324.8000, Val Loss: 36027055718.4000\n",
      "Epoch [80/300] - Train Loss: 42312693964.8000, Val Loss: 36026990592.0000\n",
      "Epoch [90/300] - Train Loss: 42312672665.6000, Val Loss: 36026890649.6000\n",
      "Epoch [100/300] - Train Loss: 42312550707.2000, Val Loss: 36026872217.6000\n",
      "Epoch [110/300] - Train Loss: 42312492646.4000, Val Loss: 36026481868.8000\n",
      "Epoch [120/300] - Train Loss: 42312545792.0000, Val Loss: 36026676019.2000\n",
      "Epoch [130/300] - Train Loss: 42312427520.0000, Val Loss: 36026988134.4000\n",
      "Epoch [140/300] - Train Loss: 42312465100.8000, Val Loss: 36026594918.4000\n",
      "Epoch [150/300] - Train Loss: 42312383488.0000, Val Loss: 36026678067.2000\n",
      "Early stopping at epoch 152\n",
      "Test loss (MSE): 34057576448.0\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# 3. Feature Selection\n",
    "# -----------------------------\n",
    "# Compute the correlation matrix using only the cleaned numeric data.\n",
    "corr_matrix = data_clean.corr()\n",
    "\n",
    "# Compute absolute correlations of features with the target and drop the target itself.\n",
    "target_corr = corr_matrix['SalePrice'].drop('SalePrice').abs().sort_values(ascending=False)\n",
    "\n",
    "# Select only the top 4 features with the highest correlation with 'SalePrice'\n",
    "top4_features = target_corr.head(4).index\n",
    "print(\"Selected top 4 features:\", list(top4_features))\n",
    "\n",
    "# Define input features (X) and target variable (y).\n",
    "X = data_clean[top4_features].values\n",
    "y = data_clean['SalePrice'].values.reshape(-1, 1)\n",
    "\n",
    "# -----------------------------\n",
    "# 4. Data Preparation & Splitting\n",
    "# -----------------------------\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Split the dataset into training and testing sets.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize only the features (do not normalize the target to keep the MSE on the original scale).\n",
    "scaler_X = StandardScaler()\n",
    "X_train_scaled = scaler_X.fit_transform(X_train)\n",
    "X_test_scaled = scaler_X.transform(X_test)\n",
    "\n",
    "# -----------------------------\n",
    "# 5. Convert Data to PyTorch Tensors and Create DataLoaders\n",
    "# -----------------------------\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
    "\n",
    "# Convert numpy arrays to float32 tensors.\n",
    "X_train_tensor = torch.tensor(X_train_scaled, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "# Create a full training dataset and split it into training and validation subsets.\n",
    "full_train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_size = int(0.8 * len(full_train_dataset))\n",
    "val_size = len(full_train_dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(full_train_dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# -----------------------------\n",
    "# 6. Define an Improved Neural Network Model using PyTorch\n",
    "# -----------------------------\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class ImprovedHousePriceNet(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(ImprovedHousePriceNet, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            \n",
    "            nn.Linear(256, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            \n",
    "            nn.Linear(128, 64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            \n",
    "            nn.Linear(64, 32),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            \n",
    "            nn.Linear(32, 1)  # Output layer for regression\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "# Initialize the model.\n",
    "input_dim = X_train_tensor.shape[1]\n",
    "model = ImprovedHousePriceNet(input_dim)\n",
    "\n",
    "# Define the loss function.\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Use Adam optimizer with weight decay to help generalization.\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "\n",
    "# -----------------------------\n",
    "# 7. Train the Model with Early Stopping and Learning Rate Scheduling\n",
    "# -----------------------------\n",
    "num_epochs = 300\n",
    "best_val_loss = float('inf')\n",
    "patience = 20  # early stopping patience\n",
    "epochs_without_improvement = 0\n",
    "\n",
    "# Learning rate scheduler to reduce LR if validation loss plateaus.\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', \n",
    "                                                 patience=10, factor=0.5, verbose=True)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Training phase\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for batch_X, batch_y in train_loader:\n",
    "        optimizer.zero_grad()               # Zero the gradients\n",
    "        outputs = model(batch_X)            # Forward pass\n",
    "        loss = criterion(outputs, batch_y)  # Compute loss\n",
    "        loss.backward()                     # Backward pass\n",
    "        optimizer.step()                    # Update parameters\n",
    "        running_loss += loss.item() * batch_X.size(0)\n",
    "    \n",
    "    train_loss = running_loss / len(train_dataset)\n",
    "    \n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for val_X, val_y in val_loader:\n",
    "            val_outputs = model(val_X)\n",
    "            loss = criterion(val_outputs, val_y)\n",
    "            val_loss += loss.item() * val_X.size(0)\n",
    "    val_loss /= len(val_dataset)\n",
    "    \n",
    "    scheduler.step(val_loss)\n",
    "    \n",
    "    # Early stopping logic.\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        best_model_state = model.state_dict()\n",
    "        epochs_without_improvement = 0\n",
    "    else:\n",
    "        epochs_without_improvement += 1\n",
    "        if epochs_without_improvement >= patience:\n",
    "            print(f\"Early stopping at epoch {epoch+1}\")\n",
    "            break\n",
    "    \n",
    "    if (epoch+1) % 10 == 0 or epoch == 0:\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}] - Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "# Load the best model weights.\n",
    "model.load_state_dict(best_model_state)\n",
    "\n",
    "# -----------------------------\n",
    "# 8. Evaluate the Model on the Test Set\n",
    "# -----------------------------\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_outputs = model(X_test_tensor)\n",
    "    test_loss = criterion(test_outputs, y_test_tensor)\n",
    "    print(\"Test loss (MSE):\", test_loss.item())\n",
    "\n",
    "# The changes above (enhanced architecture, extended training with early stopping, and tuned hyperparameters)\n",
    "# are aimed at reducing the MSE by roughly 100 times compared to our earlier baseline.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
